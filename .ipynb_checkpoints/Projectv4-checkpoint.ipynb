{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/caykroyd/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/caykroyd/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt') # for tokenization\n",
    "nltk.download('stopwords')\n",
    "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"testing_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    testing_set  = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = [element[0].split(\" \") for element in testing_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    training_set  = list(reader)\n",
    "\n",
    "training_set = [element[0].split(\" \") for element in training_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"node_information.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    node_info  = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = [element[0] for element in node_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute TFIDF vector of each paper\n",
    "corpus = [element[5] for element in node_info]\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "# each row is a node in the order of node_info\n",
    "features_TFIDF = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01249384]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "c = cosine_similarity(features_TFIDF['1001'], features_TFIDF[1:2])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = random.sample(range(len(training_set)), k=int(round(len(training_set)*0.1)))\n",
    "training_set_reduced = [training_set[i] for i in to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using training set as testing_set\n",
    "to_keep = random.sample(range(len(training_set)), k=int(round(len(training_set)*0.05)))\n",
    "testing_set_with_answers = [training_set[i] for i in to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IDs_dic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-068a0f840033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_set_reduced\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtemp_diff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIDs_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIDs_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mc_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_TFIDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIDs_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_TFIDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIDs_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mset_id1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_TFIDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIDs_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IDs_dic' is not defined"
     ]
    }
   ],
   "source": [
    "c_similarity = []\n",
    "\n",
    "# temporal distance between the papers\n",
    "temp_diff = []\n",
    "\n",
    "jaccard = []\n",
    "\n",
    "for (id1, id2, expected) in training_set_reduced:\n",
    "    temp_diff.append(int(node_info[IDs_dic[id1]][1]) - int(node_info[IDs_dic[id2]][1]))\n",
    "    c_similarity.append(cosine_similarity(features_TFIDF[IDs_dic[id1]], features_TFIDF[IDs_dic[id2]])[0][0])\n",
    "    set_id1 = set(features_TFIDF[IDs_dic[id1]].nonzero()[1])\n",
    "    set_id2 = set(features_TFIDF[IDs_dic[id2]].nonzero()[1])\n",
    "    jaccard.append(len(set_id1 & set_id2) / len(set_id1 | set_id2))\n",
    "\n",
    "temp_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = np.array([c_similarity, temp_diff, jaccard]).T\n",
    "\n",
    "training_features = preprocessing.scale(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert labels into integers then into column array\n",
    "labels = [int(element[2]) for element in training_set_reduced]\n",
    "labels = list(labels)\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "# initialize basic SVM\n",
    "classifier = svm.LinearSVC()\n",
    "\n",
    "# train\n",
    "classifier.fit(training_features, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.007893117007763996,\n",
       " 0.004746500232348903,\n",
       " 0.0,\n",
       " 0.15537955620473237,\n",
       " 0.013937202164396973,\n",
       " 0.20362681468773816,\n",
       " 0.06371675212067987,\n",
       " 0.03935835683662549,\n",
       " 0.0643673793151741,\n",
       " 0.00257789947048302,\n",
       " 0.0,\n",
       " 0.09058236190818322,\n",
       " 0.05315513339076763,\n",
       " 0.26610739974349795,\n",
       " 0.036492734864757875,\n",
       " 0.027327662211714482,\n",
       " 0.0707692283603656,\n",
       " 0.005488556560021154,\n",
       " 0.11713895244959792,\n",
       " 0.1206064613086418,\n",
       " 0.03459710750575413,\n",
       " 0.09463848554307916,\n",
       " 0.0,\n",
       " 0.04629917901113804,\n",
       " 0.08368373230637087,\n",
       " 0.2201073314156848,\n",
       " 0.5062463332159156,\n",
       " 0.16226323783775723,\n",
       " 0.22688969332763892,\n",
       " 0.03725669716431611,\n",
       " 0.00169115004883317,\n",
       " 0.0,\n",
       " 0.15885657205587733,\n",
       " 0.09637116086146748,\n",
       " 0.05077149442977331,\n",
       " 0.17123040455667243,\n",
       " 0.018146747485739613,\n",
       " 0.15930641774714477,\n",
       " 0.004215204107411644,\n",
       " 0.07661740940406031,\n",
       " 0.06793259932385559,\n",
       " 0.10410325760036457,\n",
       " 0.014505798402561483,\n",
       " 0.10844935106613791,\n",
       " 0.012156251957554145,\n",
       " 0.013955319747404694,\n",
       " 0.024485939851164498,\n",
       " 0.009707244041686394,\n",
       " 0.023364937911151372,\n",
       " 0.02740918042486187,\n",
       " 0.025998086729936407,\n",
       " 0.20981896769197161,\n",
       " 0.0,\n",
       " 0.11100875197267994,\n",
       " 0.023774345449563132,\n",
       " 0.09267335697740951,\n",
       " 0.0264033955214467,\n",
       " 0.014208755120749811,\n",
       " 0.017756150925849933,\n",
       " 0.05145846320379712,\n",
       " 0.005392817161456946,\n",
       " 0.048880137183135636,\n",
       " 0.05572088501963621,\n",
       " 0.010219315030150035,\n",
       " 0.1340758677880997,\n",
       " 0.022620220338612454,\n",
       " 0.0629896455396849,\n",
       " 0.11834889215141109,\n",
       " 0.024197629385349837,\n",
       " 0.0,\n",
       " 0.014646454909987817,\n",
       " 0.061996045946843,\n",
       " 0.004678326981449072,\n",
       " 0.0651881295029157,\n",
       " 0.009617849959075993,\n",
       " 0.0,\n",
       " 0.3275669184384266,\n",
       " 0.028644945534346468,\n",
       " 0.0838155942217797,\n",
       " 0.16443345336701562,\n",
       " 0.01613827678971351,\n",
       " 0.06611283363673402,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1288762853184216,\n",
       " 0.03857392415688521,\n",
       " 0.1255213746741397,\n",
       " 0.07233786311997223,\n",
       " 0.06639960320993857,\n",
       " 0.1193351226831886,\n",
       " 0.017337238816474424,\n",
       " 0.05249063957225823,\n",
       " 0.023315400529669572,\n",
       " 0.13323413207088614,\n",
       " 0.009841370190411149,\n",
       " 0.19075460683928588,\n",
       " 0.009738254362626325,\n",
       " 0.08914936622570768,\n",
       " 0.010922649463997904,\n",
       " 0.0029728304080700904,\n",
       " 0.025002424081163044,\n",
       " 0.04276696966208174,\n",
       " 0.02402590259337164,\n",
       " 0.07367536599676977,\n",
       " 0.18251666055671423,\n",
       " 0.005754048457902346,\n",
       " 0.025351027245157656,\n",
       " 0.13771828777661838,\n",
       " 0.17189641764928257,\n",
       " 0.23141585843572582,\n",
       " 0.16390674380679207,\n",
       " 0.032469018121236065,\n",
       " 0.026426994726012863,\n",
       " 0.0,\n",
       " 0.12295346053587178,\n",
       " 0.0,\n",
       " 0.04221242859458472,\n",
       " 0.025299143073060262,\n",
       " 0.21354594961870293,\n",
       " 0.045218355090881096,\n",
       " 0.019885803393684648,\n",
       " 0.0,\n",
       " 0.15753205629492328,\n",
       " 0.11573906251096581,\n",
       " 0.03752046227517549,\n",
       " 0.0,\n",
       " 0.17478327421699158,\n",
       " 0.015493109900243735,\n",
       " 0.04283792622822917,\n",
       " 0.4674847353798875,\n",
       " 0.059910449494516814,\n",
       " 0.1433338781902426,\n",
       " 0.03434833724531054,\n",
       " 0.07249357028314608,\n",
       " 0.003191101454104914,\n",
       " 0.2794167377345288,\n",
       " 0.12479371303808365,\n",
       " 0.135223612731203,\n",
       " 0.049580150350360154,\n",
       " 0.27373613831967847,\n",
       " 0.013456427706339353,\n",
       " 0.033052911767632344,\n",
       " 0.021377976810336347,\n",
       " 0.47652492922237266,\n",
       " 0.006349553821655787,\n",
       " 0.011991992622375245,\n",
       " 0.1352543927764837,\n",
       " 0.0527819322625834,\n",
       " 0.035938630154293355,\n",
       " 0.05193283518125821,\n",
       " 0.08098020204834933,\n",
       " 0.005320060148982924,\n",
       " 0.18278741032336915,\n",
       " 0.030873894076660274,\n",
       " 0.08260847368994301,\n",
       " 0.06673623662992342,\n",
       " 0.019112097227528053,\n",
       " 0.0070999315473890615,\n",
       " 0.022980693099478006,\n",
       " 0.0026054957776634243,\n",
       " 0.02103939891831546,\n",
       " 0.01212658432310693,\n",
       " 0.02789077922993781,\n",
       " 0.009267050056227636,\n",
       " 0.0,\n",
       " 0.47210304988547974,\n",
       " 0.11611515463202715,\n",
       " 0.15344551144548133,\n",
       " 0.1770421783309672,\n",
       " 0.06784591977367185,\n",
       " 0.0,\n",
       " 0.02327833291041433,\n",
       " 0.016228444108101637,\n",
       " 0.0774171627044533,\n",
       " 0.03993265853743406,\n",
       " 0.12150273485083034,\n",
       " 0.15719301844706593,\n",
       " 0.11263629637628776,\n",
       " 0.07562361305002081,\n",
       " 0.03798298037227055,\n",
       " 0.020124874688199925,\n",
       " 0.0733503963528297,\n",
       " 0.029609586232572836,\n",
       " 0.0765920813191691,\n",
       " 0.007971472060704029,\n",
       " 0.039000585299086975,\n",
       " 0.04307970049183042,\n",
       " 0.17611196128683426,\n",
       " 0.0952601739286845,\n",
       " 0.009695457013546667,\n",
       " 0.07997060396606184,\n",
       " 0.1471526720895018,\n",
       " 0.14028460057979983,\n",
       " 0.013438244809911076,\n",
       " 0.15846483556843283,\n",
       " 0.04916073874058109,\n",
       " 0.021660602214735918,\n",
       " 0.14200288966296729,\n",
       " 0.02424978042244413,\n",
       " 0.021101019831155067,\n",
       " 0.007641798591462535,\n",
       " 0.19018302104549006,\n",
       " 0.047772990612737966,\n",
       " 0.2266488891614753,\n",
       " 0.06580179929205111,\n",
       " 0.0,\n",
       " 0.10215748765310925,\n",
       " 0.06497694591426395,\n",
       " 0.004338512723347105,\n",
       " 0.04451887413664844,\n",
       " 0.09371571698368703,\n",
       " 0.05318401169247526,\n",
       " 0.011220636289518368,\n",
       " 0.06157131833373586,\n",
       " 0.007494397479674441,\n",
       " 0.038858961861337554,\n",
       " 0.03350557147583185,\n",
       " 0.02241450259946092,\n",
       " 0.012932467443267294,\n",
       " 0.05876277235290894,\n",
       " 0.05660221436631399,\n",
       " 0.09430900846697915,\n",
       " 0.0,\n",
       " 0.18343193856597406,\n",
       " 0.08179731946579331,\n",
       " 0.26025604859310913,\n",
       " 0.01575589054141058,\n",
       " 0.0,\n",
       " 0.026598767615397242,\n",
       " 0.07413240721699528,\n",
       " 0.00904423318942313,\n",
       " 0.03360864613746681,\n",
       " 0.024106267967892635,\n",
       " 0.031839065063286834,\n",
       " 0.011895415896139237,\n",
       " 0.13792766294916656,\n",
       " 0.2338314875620184,\n",
       " 0.04977585484974398,\n",
       " 0.1085030372099593,\n",
       " 0.29881004560554236,\n",
       " 0.09409011895628648,\n",
       " 0.07545472232599978,\n",
       " 0.027438852739547912,\n",
       " 0.13442368939523572,\n",
       " 0.2777609458132393,\n",
       " 0.07699650601622847,\n",
       " 0.0,\n",
       " 0.08456479500500383,\n",
       " 0.012276389317265225,\n",
       " 0.011617374240467751,\n",
       " 0.13745100729572804,\n",
       " 0.012289380411675335,\n",
       " 0.12025430824139867,\n",
       " 0.11426055169217905,\n",
       " 0.013107826675432609,\n",
       " 0.05059543281824642,\n",
       " 0.004012972958179575,\n",
       " 0.03053258248977786,\n",
       " 0.0011212079975879924,\n",
       " 0.026928882578901928,\n",
       " 0.17098608533002027,\n",
       " 0.09464189357828492,\n",
       " 0.013886897853146899,\n",
       " 0.04373797544115046,\n",
       " 0.04972886821324783,\n",
       " 0.05730761666992318,\n",
       " 0.02081117105065472,\n",
       " 0.007327530889950902,\n",
       " 0.09428969199156492,\n",
       " 0.056560975697228004,\n",
       " 0.11059117406260915,\n",
       " 0.21648763870783605,\n",
       " 0.01767685846231526,\n",
       " 0.18003899581336164,\n",
       " 0.0,\n",
       " 0.04317145136709776,\n",
       " 0.0,\n",
       " 0.07485444794453606,\n",
       " 0.057295041537552584,\n",
       " 0.06324344004818182,\n",
       " 0.0,\n",
       " 0.14177788984683182,\n",
       " 0.03676006466241189,\n",
       " 0.006613343436754528,\n",
       " 0.12442787956026546,\n",
       " 0.1632629953165708,\n",
       " 0.03251624468390964,\n",
       " 0.0,\n",
       " 0.1152130526423718,\n",
       " 0.1394672473304789,\n",
       " 0.13901826691199642,\n",
       " 0.06934699832247275,\n",
       " 0.004979557167912994,\n",
       " 0.12027471408479644,\n",
       " 0.03999150231599629,\n",
       " 0.19156840645636627,\n",
       " 0.16626857877384313,\n",
       " 0.02354086383621418,\n",
       " 0.15488092917560267,\n",
       " 0.14290438056926155,\n",
       " 0.04778919902982179,\n",
       " 0.07122629804285259,\n",
       " 0.008277472342199124,\n",
       " 0.15979200719629927,\n",
       " 0.4790800311735014,\n",
       " 0.01610198038731132,\n",
       " 0.31751060673595133,\n",
       " 0.15959807719094934,\n",
       " 0.016196489477213097,\n",
       " 0.139507378173754,\n",
       " 0.22892203353581256,\n",
       " 0.203874234214651,\n",
       " 0.17397735050756652,\n",
       " 0.010126507891533002,\n",
       " 0.09279068768587523,\n",
       " 0.04299030838390643,\n",
       " 0.16090955743248855,\n",
       " 0.07030276377451072,\n",
       " 0.06871471897871147,\n",
       " 0.35774775994369434,\n",
       " 0.00815202373154048,\n",
       " 0.05454350598247435,\n",
       " 0.06860684586020022,\n",
       " 0.021117369137530134,\n",
       " 0.0331061894035742,\n",
       " 0.011264676047011384,\n",
       " 0.05153056223840356,\n",
       " 0.20671941957403556,\n",
       " 0.02263371320346567,\n",
       " 0.07990982955919446,\n",
       " 0.040479710310168664,\n",
       " 0.014811197023307352,\n",
       " 0.10587095619332387,\n",
       " 0.028703801021714694,\n",
       " 0.0521200714334991,\n",
       " 0.04973069304196404,\n",
       " 0.042347492330462276,\n",
       " 0.046450191529033735,\n",
       " 0.028551489403598102,\n",
       " 0.030212910112872447,\n",
       " 0.04303289151350077,\n",
       " 0.10093552745553451,\n",
       " 0.0,\n",
       " 0.0424876236214769,\n",
       " 0.0019797282808665315,\n",
       " 0.06263281827340629,\n",
       " 0.017857924269148014,\n",
       " 0.027278693344185815,\n",
       " 0.07030698358295545,\n",
       " 0.09399901018336307,\n",
       " 0.28297172900037526,\n",
       " 0.10342969008044751,\n",
       " 0.047578037208591314,\n",
       " 0.004248410750826598,\n",
       " 0.11858301346749517,\n",
       " 0.09681178266450076,\n",
       " 0.043716255239336296,\n",
       " 0.31871204090420546,\n",
       " 0.17438380855804794,\n",
       " 0.024365274615952524,\n",
       " 0.03451175323561361,\n",
       " 0.059112021496149574,\n",
       " 0.04923486538974976,\n",
       " 0.0,\n",
       " 0.10834295845237035,\n",
       " 0.022298175901759466,\n",
       " 0.014898071441165825,\n",
       " 0.33306073772794564,\n",
       " 0.006925638174939077,\n",
       " 0.004940490043073222,\n",
       " 0.051795035087812365,\n",
       " 0.007259595764157061,\n",
       " 0.06494644775835687,\n",
       " 0.08153198973510649,\n",
       " 0.005682933115072501,\n",
       " 0.006211254115015113,\n",
       " 0.28114558872592454,\n",
       " 0.2722201295590608,\n",
       " 0.014726617154070329,\n",
       " 0.0,\n",
       " 0.2531746648456189,\n",
       " 0.1391480292990399,\n",
       " 0.0,\n",
       " 0.02464149815021798,\n",
       " 0.003197948102405454,\n",
       " 0.1322388358628153,\n",
       " 0.12330699440577679,\n",
       " 0.06648899803804448,\n",
       " 0.0,\n",
       " 0.05591307536005609,\n",
       " 0.3223400825994236,\n",
       " 0.01492707636999015,\n",
       " 0.049834893593377026,\n",
       " 0.07339187751407718,\n",
       " 0.01733585477167489,\n",
       " 0.019381635546310155,\n",
       " 0.07689171382297615,\n",
       " 0.0035975355883677176,\n",
       " 0.007418952112907118,\n",
       " 0.1215770928973063,\n",
       " 0.04187116931527009,\n",
       " 0.03236418270797096,\n",
       " 0.1035753032063888,\n",
       " 0.005068061807758113,\n",
       " 0.007722934183755034,\n",
       " 0.010563257341344046,\n",
       " 0.0968563004465865,\n",
       " 0.14955378019488233,\n",
       " 0.02712860141970221,\n",
       " 0.047582122242814474,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.07240954387061146,\n",
       " 0.007196239198151192,\n",
       " 0.017441130680339176,\n",
       " 0.08652660917620023,\n",
       " 0.06593921871264494,\n",
       " 0.08071254779123276,\n",
       " 0.1526747691651676,\n",
       " 0.17014045742951922,\n",
       " 0.03689863458206752,\n",
       " 0.05305685174725394,\n",
       " 0.011771933041534701,\n",
       " 0.24423912682603094,\n",
       " 0.03774626320108905,\n",
       " 0.0,\n",
       " 0.1739092505565195,\n",
       " 0.037480558560581106,\n",
       " 0.13000347064420228,\n",
       " 0.09007314493031338,\n",
       " 0.06389203081113859,\n",
       " 0.011925890984104588,\n",
       " 0.04541889834951085,\n",
       " 0.021019032156387313,\n",
       " 0.21545995455859493,\n",
       " 0.015067275098912696,\n",
       " 0.012460244789676448,\n",
       " 0.06378451141828745,\n",
       " 0.04933648830492332,\n",
       " 0.0,\n",
       " 0.03218386000624238,\n",
       " 0.21470954599298406,\n",
       " 0.07010393024808433,\n",
       " 0.08469298549541783,\n",
       " 0.01708824855360907,\n",
       " 0.0023400690276689493,\n",
       " 0.0772213181471188,\n",
       " 0.08040656221374669,\n",
       " 0.0,\n",
       " 0.12551123590033889,\n",
       " 0.012361852684088603,\n",
       " 0.031657962323480844,\n",
       " 0.0835014058599351,\n",
       " 0.0838212679642099,\n",
       " 0.004689859016736052,\n",
       " 0.041123681749715216,\n",
       " 0.11374622663617348,\n",
       " 0.037461004850370114,\n",
       " 0.1739302957934314,\n",
       " 0.06451402910429357,\n",
       " 0.11958593451844762,\n",
       " 0.0,\n",
       " 0.2506660869999274,\n",
       " 0.25028801792062816,\n",
       " 0.09754232366069758,\n",
       " 0.15756876204461617,\n",
       " 0.019687563733283207,\n",
       " 0.05751190348592831,\n",
       " 0.021927632417190847,\n",
       " 0.012445691956404218,\n",
       " 0.209107453913838,\n",
       " 0.19011037515092696,\n",
       " 0.24342018843110388,\n",
       " 0.02392084995155067,\n",
       " 0.019470094326605902,\n",
       " 0.29425219911243483,\n",
       " 0.04683239782597228,\n",
       " 0.034024813147682555,\n",
       " 0.05522202089883482,\n",
       " 0.25232938346810846,\n",
       " 0.1689498249935452,\n",
       " 0.04871804184955353,\n",
       " 0.07277764025769953,\n",
       " 0.024156644760489822,\n",
       " 0.020955872332643833,\n",
       " 0.0,\n",
       " 0.10878730353435562,\n",
       " 0.19142314873043131,\n",
       " 0.004538277747547993,\n",
       " 0.045453791294922836,\n",
       " 0.025174963052747114,\n",
       " 0.0479822688631507,\n",
       " 0.0120931925811119,\n",
       " 0.0900373718731918,\n",
       " 0.07696145664128777,\n",
       " 0.22242720164306534,\n",
       " 0.0,\n",
       " 0.008878455085314263,\n",
       " 0.0,\n",
       " 0.04410877741081477,\n",
       " 0.03250981146311758,\n",
       " 0.1295394595527497,\n",
       " 0.052997215041300956,\n",
       " 0.03337011734504433,\n",
       " 0.0037231686048353864,\n",
       " 0.0,\n",
       " 0.052357910591108905,\n",
       " 0.26195479645055975,\n",
       " 0.01316397377217969,\n",
       " 0.18198048878162487,\n",
       " 0.2791557799360812,\n",
       " 0.5055920816016313,\n",
       " 0.08779525388773951,\n",
       " 0.24248941003839594,\n",
       " 0.0,\n",
       " 0.04139384543558618,\n",
       " 0.03293866433291967,\n",
       " 0.0022465546439903064,\n",
       " 0.021044205647264773,\n",
       " 0.2192041902399166,\n",
       " 0.10212451034467476,\n",
       " 0.36840922403204157,\n",
       " 0.12186080516745719,\n",
       " 0.031388229310681554,\n",
       " 0.0,\n",
       " 0.1127131109168611,\n",
       " 0.033689462467778326,\n",
       " 0.08749955666951718,\n",
       " 0.09938344392991633,\n",
       " 0.0,\n",
       " 0.35878477120238333,\n",
       " 0.026390433063260058,\n",
       " 0.2491123143030703,\n",
       " 0.29433860262342576,\n",
       " 0.0,\n",
       " 0.012655196615795013,\n",
       " 0.01592649402881195,\n",
       " 0.049798863311582606,\n",
       " 0.10620811062678148,\n",
       " 0.01279758894327823,\n",
       " 0.03158740244746714,\n",
       " 0.02129430911096779,\n",
       " 0.04547237806122107,\n",
       " 0.10158298836757626,\n",
       " 0.12407894972762923,\n",
       " 0.1468902763964038,\n",
       " 0.02067658517260891,\n",
       " 0.08203025874981303,\n",
       " 0.06446945037071626,\n",
       " 0.02637814273334482,\n",
       " 0.12164436721986557,\n",
       " 0.0,\n",
       " 0.28055876752157555,\n",
       " 0.015456046758886328,\n",
       " 0.28134589606048827,\n",
       " 0.018913406640330213,\n",
       " 0.0213696443972973,\n",
       " 0.03198663767351339,\n",
       " 0.03993736808158406,\n",
       " 0.018150558802575878,\n",
       " 0.028793514276351434,\n",
       " 0.024058663813299446,\n",
       " 0.07557566449933259,\n",
       " 0.13022411461954583,\n",
       " 0.023805659857026634,\n",
       " 0.0,\n",
       " 0.00912893061383094,\n",
       " 0.1120561843368697,\n",
       " 0.10249560984477422,\n",
       " 0.011277433540236805,\n",
       " 0.0,\n",
       " 0.016748661669061936,\n",
       " 0.010770802706018203,\n",
       " 0.08048339229524,\n",
       " 0.0,\n",
       " 0.17114357418868426,\n",
       " 0.02004004683650512,\n",
       " 0.07674017992620535,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.06113849278206292,\n",
       " 0.023543423212810468,\n",
       " 0.03526717806430034,\n",
       " 0.0,\n",
       " 0.011069811202465196,\n",
       " 0.003775478922217137,\n",
       " 0.06296181863343453,\n",
       " 0.2703110209605033,\n",
       " 0.0,\n",
       " 0.2566714201090412,\n",
       " 0.019733000126001737,\n",
       " 0.04126436875557549,\n",
       " 0.01802816266884274,\n",
       " 0.14793837700495918,\n",
       " 0.0286071600634439,\n",
       " 0.07698011067851075,\n",
       " 0.23592422663654655,\n",
       " 0.10944942384856707,\n",
       " 0.507813066296668,\n",
       " 0.05063966442841863,\n",
       " 0.038682365083782054,\n",
       " 0.024058061880441312,\n",
       " 0.003011246235995973,\n",
       " 0.17448674934179298,\n",
       " 0.034886504173623364,\n",
       " 0.012686863346003312,\n",
       " 0.20891352533001664,\n",
       " 0.02371410250734642,\n",
       " 0.0,\n",
       " 0.017074498426108437,\n",
       " 0.0,\n",
       " 0.1237846914352683,\n",
       " 0.02741568655523092,\n",
       " 0.02001781191200557,\n",
       " 0.010195294944350123,\n",
       " 0.08256345159791181,\n",
       " 0.08527500139174692,\n",
       " 0.03196065401316606,\n",
       " 0.0,\n",
       " 0.10933983128760322,\n",
       " 0.038798610847496015,\n",
       " 0.2697804197157048,\n",
       " 0.05868266208120625,\n",
       " 0.007375704568658116,\n",
       " 0.08741150030728476,\n",
       " 0.04860847612345105,\n",
       " 0.0517232488700512,\n",
       " 0.0278456505936971,\n",
       " 0.007896720613374791,\n",
       " 0.010429313948339172,\n",
       " 0.014297818351639196,\n",
       " 0.0653412827377031,\n",
       " 0.05583018110217163,\n",
       " 0.02419219229014947,\n",
       " 0.02344364099844978,\n",
       " 0.0,\n",
       " 0.16389963254563072,\n",
       " 0.2385162657635896,\n",
       " 0.006897529049182087,\n",
       " 0.28895137709432495,\n",
       " 0.23605108330490904,\n",
       " 0.06282047222116989,\n",
       " 0.004083149148194156,\n",
       " 0.010016535974043655,\n",
       " 0.18454020643477817,\n",
       " 0.019774277449551396,\n",
       " 0.1340116231395328,\n",
       " 0.0,\n",
       " 0.008781761977287111,\n",
       " 0.08263595827322137,\n",
       " 0.0,\n",
       " 0.02936905330515476,\n",
       " 0.0,\n",
       " 0.03026011867733902,\n",
       " 0.09042985950631269,\n",
       " 0.09917161843276556,\n",
       " 0.13348217232792928,\n",
       " 0.05703130097538997,\n",
       " 0.014461331107952483,\n",
       " 0.007227644016522671,\n",
       " 0.015925456339460985,\n",
       " 0.12885231553254645,\n",
       " 0.03129224786201828,\n",
       " 0.0,\n",
       " 0.07878299064727555,\n",
       " 0.009425991427363256,\n",
       " 0.07628735414834263,\n",
       " 0.02080240153976992,\n",
       " 0.025795586325900587,\n",
       " 0.18939228567271393,\n",
       " 0.04386817001224885,\n",
       " 0.021410398722981224,\n",
       " 0.07556987117185456,\n",
       " 0.00983541476206658,\n",
       " 0.01945321524737051,\n",
       " 0.052617288753281435,\n",
       " 0.07794242917217756,\n",
       " 0.0,\n",
       " 0.023490178229770363,\n",
       " 0.18935714183637492,\n",
       " 0.0,\n",
       " 0.09773711737691766,\n",
       " 0.20924821934031912,\n",
       " 0.021196649802183762,\n",
       " 0.013158797077328463,\n",
       " 0.0356067123211593,\n",
       " 0.15800826498022016,\n",
       " 0.028684962308426393,\n",
       " 0.04546017384519708,\n",
       " 0.0,\n",
       " 0.030197103564857594,\n",
       " 0.14425088291867527,\n",
       " 0.03511034703345138,\n",
       " 0.04235151595808648,\n",
       " 0.1999019183988931,\n",
       " 0.03657170416621902,\n",
       " 0.0,\n",
       " 0.060751645966308734,\n",
       " 0.03363016834853637,\n",
       " 0.0,\n",
       " 0.02095063401294419,\n",
       " 0.12537200062097253,\n",
       " 0.057807577755214515,\n",
       " 0.13562604778794798,\n",
       " 0.07936918713342925,\n",
       " 0.12828842229691134,\n",
       " 0.4312505603594137,\n",
       " 0.04581209644328417,\n",
       " 0.008528671008635864,\n",
       " 0.025429469079400052,\n",
       " 0.16038570696412735,\n",
       " 0.09893245139732401,\n",
       " 0.09574928325526302,\n",
       " 0.08045493135989408,\n",
       " 0.03173562681647592,\n",
       " 0.003116405965124114,\n",
       " 0.06827829887910117,\n",
       " 0.02498744302596028,\n",
       " 0.015351891611536569,\n",
       " 0.03371508006747516,\n",
       " 0.10956555837347223,\n",
       " 0.11614341353819738,\n",
       " 0.017462142682513268,\n",
       " 0.14286824107488083,\n",
       " 0.05324004842097981,\n",
       " 0.04030079099177311,\n",
       " 0.13806065884066734,\n",
       " 0.0,\n",
       " 0.18507011830501557,\n",
       " 0.052052502821048965,\n",
       " 0.009946717887922674,\n",
       " 0.1510696019830645,\n",
       " 0.0,\n",
       " 0.01724773132216856,\n",
       " 0.24622589375059475,\n",
       " 0.7684775526491474,\n",
       " 0.0,\n",
       " 0.0405050542599468,\n",
       " 0.04785821626841679,\n",
       " 0.2210960279495332,\n",
       " 0.032055679614857086,\n",
       " 0.011557810142129029,\n",
       " 0.12444931645505744,\n",
       " 0.05430573727202658,\n",
       " 0.021595044059456107,\n",
       " 0.13917480904118137,\n",
       " 0.221089626852885,\n",
       " 0.4227933049422188,\n",
       " 0.3187201453112297,\n",
       " 0.034049476292008794,\n",
       " 0.05725382549095331,\n",
       " 0.05756782213636057,\n",
       " 0.19636830407594055,\n",
       " 0.1321368910676545,\n",
       " 0.027514019339094954,\n",
       " 0.027377450527261805,\n",
       " 0.14639319515814905,\n",
       " 0.19528826311058087,\n",
       " 0.2825098558460069,\n",
       " 0.23527888947545988,\n",
       " 0.021779498749726497,\n",
       " 0.0,\n",
       " 0.011891228190158403,\n",
       " 0.0320501760267288,\n",
       " 0.04059536923117481,\n",
       " 0.0,\n",
       " 0.11890902109845293,\n",
       " 0.15614961208308203,\n",
       " 0.04774340392299508,\n",
       " 0.09970100643378747,\n",
       " 0.04163942014652049,\n",
       " 0.11641214572645445,\n",
       " 0.01063015160021286,\n",
       " 0.02831640573315067,\n",
       " 0.02156948671761065,\n",
       " 0.3382698197656431,\n",
       " 0.03585503239778295,\n",
       " 0.05537076296604631,\n",
       " 0.04558801088451742,\n",
       " 0.03624032143348253,\n",
       " 0.02712107462024183,\n",
       " 0.024731439724187912,\n",
       " 0.09849009736574826,\n",
       " 0.0770143327314946,\n",
       " 0.20057698204052335,\n",
       " 0.02509874789690248,\n",
       " 0.01482420014151861,\n",
       " 0.06350513218569498,\n",
       " 0.008927456049351303,\n",
       " 0.01485620540994578,\n",
       " 0.08107996579769218,\n",
       " 0.20295772599458226,\n",
       " 0.12657287210574356,\n",
       " 0.0,\n",
       " 0.013237838382028697,\n",
       " 0.19720468935390853,\n",
       " 0.0625761381656231,\n",
       " 0.04482904453535087,\n",
       " 0.0069938176053742215,\n",
       " 0.16030341633323328,\n",
       " 0.03260760618137303,\n",
       " 0.0,\n",
       " 0.07901703159407689,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.009644850779617298,\n",
       " 0.01646291045964089,\n",
       " 0.2513653127443926,\n",
       " 0.4146117480788142,\n",
       " 0.005708129592208263,\n",
       " 0.036868340967069826,\n",
       " 0.2991127777738224,\n",
       " 0.029438717623454447,\n",
       " 0.006591329526754294,\n",
       " 0.04066016092738549,\n",
       " 0.010706832869190146,\n",
       " 0.012088237432810886,\n",
       " 0.06466883667928558,\n",
       " 0.13494867193703472,\n",
       " 0.09925392944060422,\n",
       " 0.1665726715605103,\n",
       " 0.0654632643715703,\n",
       " 0.08884062103849964,\n",
       " 0.0587370182520925,\n",
       " 0.00419628720566634,\n",
       " 0.01145702677537892,\n",
       " 0.019801792132694583,\n",
       " 0.023672257750026446,\n",
       " 0.0066382004194045306,\n",
       " 0.012407149801601423,\n",
       " 0.0,\n",
       " 0.05717743159077998,\n",
       " 0.15203720523873673,\n",
       " 0.005499092212498807,\n",
       " 0.05574991249594776,\n",
       " 0.15092101807061434,\n",
       " 0.14331566633300155,\n",
       " 0.022242092648939858,\n",
       " 0.21760662441859002,\n",
       " 0.28755090602133665,\n",
       " 0.14058681554259506,\n",
       " 0.12442093074249784,\n",
       " 0.031750943183620296,\n",
       " 0.09404420934557253,\n",
       " 0.4209217368185439,\n",
       " 0.0,\n",
       " 0.01734468935683743,\n",
       " 0.027138986520990956,\n",
       " 0.0018429762314865815,\n",
       " 0.07575956585845225,\n",
       " 0.1575541365679345,\n",
       " 0.025830041632236397,\n",
       " 0.17271765621076668,\n",
       " 0.06699749219278653,\n",
       " 0.39450103034171036,\n",
       " 0.010176466522157254,\n",
       " 0.012855480182858875,\n",
       " 0.04626038541026356,\n",
       " 0.09721651040577702,\n",
       " 0.19442950133499726,\n",
       " 0.18275887745438127,\n",
       " 0.04811508396380805,\n",
       " 0.0,\n",
       " 0.007528476547549065,\n",
       " 0.04424299496011756,\n",
       " 0.018657937503418202,\n",
       " 0.07638823429392705,\n",
       " 0.007030151093683406,\n",
       " 0.031100896934286526,\n",
       " 0.028917124063358807,\n",
       " 0.025591996404586544,\n",
       " 0.011088061584480943,\n",
       " 0.05732076608037749,\n",
       " 0.0,\n",
       " 0.06630517379796921,\n",
       " 0.0,\n",
       " 0.025235623875752344,\n",
       " 0.16137038707910875,\n",
       " 0.012618245064839486,\n",
       " 0.03180022907938752,\n",
       " 0.1195054906510479,\n",
       " 0.10492688494296602,\n",
       " 0.12553165059356222,\n",
       " 0.16295352226466847,\n",
       " 0.052619122792358836,\n",
       " 0.0,\n",
       " 0.26583903579219065,\n",
       " 0.02327438245755021,\n",
       " 0.07711868906145541,\n",
       " 0.007455198614564193,\n",
       " 0.00848028821167383,\n",
       " 0.04465612903614735,\n",
       " 0.0,\n",
       " 0.012382400322132964,\n",
       " 0.09893441622576046,\n",
       " 0.09954286935927577,\n",
       " 0.07571623725263843,\n",
       " 0.040164645381635236,\n",
       " 0.0758668196093488,\n",
       " 0.03998937881243752,\n",
       " 0.027015308211253246,\n",
       " 0.048796301679025225,\n",
       " 0.06042569496099859,\n",
       " 0.026722419064612254,\n",
       " 0.0,\n",
       " 0.15188434773262086,\n",
       " 0.0,\n",
       " 0.02486737973280937,\n",
       " 0.03264543643404596,\n",
       " 0.13280660538439518,\n",
       " 0.11987469140769591,\n",
       " 0.0,\n",
       " 0.027185436730222237,\n",
       " 0.04389865288490457,\n",
       " 0.01847132234105294,\n",
       " 0.0,\n",
       " 0.06568194839408566,\n",
       " 0.03718573320322316,\n",
       " 0.09150640869553192,\n",
       " 0.14254359559531812,\n",
       " 0.041615530931841935,\n",
       " 0.005331771505898062,\n",
       " 0.06978242313436378,\n",
       " 0.05645105689450157,\n",
       " 0.007992014364615153,\n",
       " 0.12916779869891618,\n",
       " 0.03678732305735369,\n",
       " 0.2372221967181805,\n",
       " 0.043221462470118585,\n",
       " 0.01586645821955508,\n",
       " 0.016254189441979802,\n",
       " 0.01334061539899077,\n",
       " 0.006553895015473785,\n",
       " 0.08491841418275368,\n",
       " 0.30378761389759956,\n",
       " 0.1865842855075433,\n",
       " 0.0,\n",
       " 0.06071060716817871,\n",
       " 0.05199846316036409,\n",
       " 0.1873265931960014,\n",
       " 0.10597829163698416,\n",
       " 0.06443830486154203,\n",
       " 0.002289805329312205,\n",
       " 0.010558331978742591,\n",
       " 0.25452474501906786,\n",
       " 0.007816927315076543,\n",
       " 0.03750830580534471,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.22845520800964772,\n",
       " 0.0,\n",
       " 0.09869154112996974,\n",
       " 0.27021438382638163,\n",
       " 0.07025571106239327,\n",
       " 0.026102357875247187,\n",
       " 0.007826260596273185,\n",
       " 0.01809063304163403,\n",
       " 0.003664245423391975,\n",
       " 0.028358683465653678,\n",
       " 0.0,\n",
       " 0.02909554781424461,\n",
       " 0.08637861267398395,\n",
       " 0.06348716774576699,\n",
       " 0.24702768401816064,\n",
       " 0.09752663030148821,\n",
       " 0.0015985738048098488,\n",
       " 0.026551223775998573,\n",
       " 0.0,\n",
       " 0.013523230084135461,\n",
       " 0.07284533016053174,\n",
       " 0.06110027594527907,\n",
       " 0.0015169546344570167,\n",
       " 0.21654662395763077,\n",
       " 0.09611360259873666,\n",
       " 0.02386330803501242,\n",
       " 0.1906594838712686,\n",
       " 0.07624311316261734,\n",
       " 0.018821311671782505,\n",
       " 0.08594860204584784,\n",
       " 0.023454413074410516,\n",
       " 0.21962823500585246,\n",
       " 0.09339761594739057,\n",
       " 0.1325743355564126,\n",
       " 0.08708883701426877,\n",
       " 0.0,\n",
       " 0.012831238259850587,\n",
       " 0.052002126355761215,\n",
       " 0.12536712995826169,\n",
       " 0.2999956111829275,\n",
       " 0.031209741060581813,\n",
       " 0.06251648569633078,\n",
       " 0.16583784643294663,\n",
       " 0.0826756814483568,\n",
       " 0.029344648266107772,\n",
       " 0.062258568385403876,\n",
       " 0.06283347191456001,\n",
       " 0.05287513618205072,\n",
       " 0.1519235161493257,\n",
       " 0.0,\n",
       " 0.11678991970896613,\n",
       " ...]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_similarity_test = []\n",
    "\n",
    "temp_diff_test = []\n",
    "\n",
    "jaccard_test = []\n",
    "    \n",
    "for (id1, id2, expected) in testing_set_with_answers:\n",
    "    temp_diff_test.append(int(node_info[IDs_dic[id1]][1]) - int(node_info[IDs_dic[id2]][1]))\n",
    "    c_similarity_test.append(cosine_similarity(features_TFIDF[IDs_dic[id1]], features_TFIDF[IDs_dic[id2]])[0][0])\n",
    "    set_id1 = set(features_TFIDF[IDs_dic[id1]].nonzero()[1])\n",
    "    set_id2 = set(features_TFIDF[IDs_dic[id2]].nonzero()[1])\n",
    "    jaccard_test.append(len(set_id1 & set_id2) / len(set_id1 | set_id2))\n",
    "    if(temp_diff_test[-1] < 0):\n",
    "        c_similarity_test[-1] = 0\n",
    "        jaccard_test[-1] = 0\n",
    "c_similarity_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of lists into array\n",
    "# documents as rows, unique words as columns (i.e., example as rows, features as columns)\n",
    "testing_features = np.array([c_similarity_test, temp_diff_test, jaccard_test]).T\n",
    "\n",
    "# scale\n",
    "testing_features = preprocessing.scale(testing_features)\n",
    "\n",
    "# issue predictions\n",
    "predictions_SVM = list(classifier.predict(testing_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8314995673136357\n"
     ]
    }
   ],
   "source": [
    "tp = 0 #true positive\n",
    "fp = 0 #false positive\n",
    "fn = 0 #false negative\n",
    "    \n",
    "for i in range(len(testing_set_with_answers)):\n",
    "    if predictions_SVM[i] == 1 and int(testing_set_with_answers[i][2]) == 1:\n",
    "        tp += 1\n",
    "    elif predictions_SVM[i] == 1 and int(testing_set_with_answers[i][2]) == 0:\n",
    "        fp += 1\n",
    "    elif int(testing_set_with_answers[i][2]) == 1:\n",
    "        fn += 1\n",
    "    \n",
    "p = tp/(tp+fp) #precision\n",
    "r = tp/(tp+fn) #recall\n",
    "f = (2*p*r)/(p+r)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LSA. Use algorithm = \"randomized\" for large datasets\n",
    "components = 3\n",
    "lsa = TruncatedSVD(components, algorithm = 'randomized')\n",
    "dtm_lsa = lsa.fit_transform(features_TFIDF)\n",
    "dtm_lsa = preprocessing.Normalizer(copy=False).fit_transform(dtm_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [w[0] for w in dtm_lsa]\n",
    "ys = [w[1] for w in dtm_lsa]\n",
    "zs = [w[2] for w in dtm_lsa]\n",
    "#qs = [w[3] for w in dtm_lsa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f', 'dist']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "figure()\n",
    "plt.scatter(xs, ys)\n",
    "xlabel('First principal component')\n",
    "ylabel('Seconf principal component')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01292476]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radius = np.arange(0.05, 1, 0.05)\n",
    "IDs_dic = dict(zip(IDs,range(len(IDs))))\n",
    "cosine_similarity(features_TFIDF[IDs_dic['1001']], features_TFIDF[IDs_dic['1002']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257276 22168 77854 0.9206710467929173 0.7676901500910095 0.8372498673878166\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-ab4be0246e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_TFIDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIDs_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_TFIDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIDs_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIDs_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIDs_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n\u001b[0;32m--> 905\u001b[0;31m                         dense_output=dense_output)\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \"\"\"\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toarray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mmajor_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# convert to this format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         idx_dtype = get_index_dtype((self.indptr, self.indices,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Format {} is unknown.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m###################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/csc.py\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    151\u001b[0m                   data)\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_sorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "F1 = []\n",
    "\n",
    "for epsilon in radius:\n",
    "    tp = 0 #true positive\n",
    "    fp = 0 #false positive\n",
    "    fn = 0 #false negative\n",
    "\n",
    "    for (id1, id2, expected) in training_set:\n",
    "        predicted = cosine_similarity(features_TFIDF[IDs_dic[id1]], features_TFIDF[IDs_dic[id2]])[0][0] >= epsilon and int(node_info[IDs_dic[id1]][1]) >= int(node_info[IDs_dic[id2]][1])\n",
    "        if (predicted == True and expected == '1'):\n",
    "            tp += 1\n",
    "        elif (predicted == True and expected == '0'):\n",
    "            fp += 1\n",
    "        elif (expected == '1'):\n",
    "            fn += 1\n",
    "\n",
    "    p = tp/(tp+fp) #precision\n",
    "    r = tp/(tp+fn) #recall\n",
    "    f = (2*p*r)/(p+r)\n",
    "    \n",
    "    print(tp,fp,fn,p,r,f)\n",
    "\n",
    "    F1.append(f)\n",
    "\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.000445648686227673,\n",
       " 0.0010015883175686889,\n",
       " 0.0018483305972528967,\n",
       " 0.0031842643291894812,\n",
       " 0.0053814276542345175,\n",
       " 0.008392466459073704,\n",
       " 0.012846333895814055,\n",
       " 0.018750919440075137,\n",
       " 0.026385047729503078,\n",
       " 0.03713421782048052,\n",
       " 0.05081545064377682,\n",
       " 0.06893899759338705,\n",
       " 0.09196015246279211,\n",
       " 0.12261968932229138,\n",
       " 0.16337538426932594,\n",
       " 0.2175609367250053,\n",
       " 0.29133009788599157,\n",
       " 0.39524096027572275,\n",
       " 0.5476837060702876]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plt.scatter(radius, F1)\n",
    "show()\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train_raw = corpus\n",
    "y_train_labels = raw_text_dataset[1] \n",
    "X_test_raw = raw_text_dataset[2]\n",
    "y_test_labels = raw_text_dataset[3]\n",
    "\n",
    "# The Reuters dataset consists of ~100 categories. However, we are going to\n",
    "# simplify this to a binary classification problem. The 'positive class' will\n",
    "# be the articles related to \"acquisitions\" (or \"acq\" in the dataset). All\n",
    "# other articles will be negative.\n",
    "y_train = [\"acq\" in y for y in y_train_labels]\n",
    "y_test = [\"acq\" in y for y in y_test_labels]\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=10000,\n",
    "                             min_df=2, stop_words='english',\n",
    "                             use_idf=True)\n",
    "\n",
    "# Build the tfidf vectorizer from the training data (\"fit\"), and apply it \n",
    "# (\"transform\").\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "print(\"  Actual number of tfidf features: %d\" % X_train_tfidf.get_shape()[1])\n",
    "\n",
    "print(\"\\nPerforming dimensionality reduction using LSA\")\n",
    "t0 = time.time()\n",
    "\n",
    "# Project the tfidf vectors onto the first N principal components.\n",
    "# Though this is significantly fewer features than the original tfidf vector,\n",
    "# they are stronger features, and the accuracy is higher.\n",
    "svd = TruncatedSVD(100)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "\n",
    "print(\"  done in %.3fsec\" % (time.time() - t0))\n",
    "\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"  Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))\n",
    "\n",
    "\n",
    "# Now apply the transformations to the test data as well.\n",
    "X_test_tfidf = vectorizer.transform(X_test_raw)\n",
    "X_test_lsa = lsa.transform(X_test_tfidf)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#  Run classification of the test articles\n",
    "###############################################################################\n",
    "\n",
    "print(\"\\nClassifying tfidf vectors...\")\n",
    "\n",
    "# Time this step.\n",
    "t0 = time.time()\n",
    "\n",
    "# Build a k-NN classifier. Use k = 5 (majority wins), the cosine distance, \n",
    "# and brute-force calculation of distances.\n",
    "knn_tfidf = KNeighborsClassifier(n_neighbors=5, algorithm='brute', metric='cosine')\n",
    "knn_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Classify the test vectors.\n",
    "p = knn_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Measure accuracy\n",
    "numRight = 0;\n",
    "for i in range(0,len(p)):\n",
    "    if p[i] == y_test[i]:\n",
    "        numRight += 1\n",
    "\n",
    "print(\"  (%d / %d) correct - %.2f%%\" % (numRight, len(y_test), float(numRight) / float(len(y_test)) * 100.0))\n",
    "\n",
    "# Calculate the elapsed time (in seconds)\n",
    "elapsed = (time.time() - t0)\n",
    "print(\"  done in %.3fsec\" % elapsed)\n",
    "\n",
    "\n",
    "print(\"\\nClassifying LSA vectors...\")\n",
    "\n",
    "# Time this step.\n",
    "t0 = time.time()\n",
    "\n",
    "# Build a k-NN classifier. Use k = 5 (majority wins), the cosine distance, \n",
    "# and brute-force calculation of distances.\n",
    "knn_lsa = KNeighborsClassifier(n_neighbors=5, algorithm='brute', metric='cosine')\n",
    "knn_lsa.fit(X_train_lsa, y_train)\n",
    "\n",
    "# Classify the test vectors.\n",
    "p = knn_lsa.predict(X_test_lsa)\n",
    "\n",
    "# Measure accuracy\n",
    "numRight = 0;\n",
    "for i in range(0,len(p)):\n",
    "    if p[i] == y_test[i]:\n",
    "        numRight += 1\n",
    "\n",
    "print(\"  (%d / %d) correct - %.2f%%\" % (numRight, len(y_test), float(numRight) / float(len(y_test)) * 100.0))\n",
    "\n",
    "# Calculate the elapsed time (in seconds)\n",
    "elapsed = (time.time() - t0)    \n",
    "print(\"    done in %.3fsec\" % elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
